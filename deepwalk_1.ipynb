{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepwalk_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyadRUkRYub8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import random\n",
        "import functools\n",
        "# from similarities import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIENslwXZwQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_restaurant_dataset():\n",
        "    path = 'dataset_ubicomp2013_checkins.txt'\n",
        "#     lines = (line.decode('utf-8') for line in path)\n",
        "    infile = open(path, 'r')\n",
        "    a = set()\n",
        "    b = set()\n",
        "    edges = []\n",
        "    for line in infile:\n",
        "        s=line.strip().split(None)\n",
        "        u=-1*int(s.pop(0)) -10\n",
        "        v=int(s.pop(0))\n",
        "        a.add(u)\n",
        "        b.add(v)\n",
        "        edges.append((u,v))\n",
        "    top_nodes = {}\n",
        "    bottom_nodes = {}\n",
        "    count = 0 \n",
        "    for x in a:\n",
        "        top_nodes[x] = count\n",
        "        count = count + 1\n",
        "    count  = 0    \n",
        "    for y in b:\n",
        "        bottom_nodes[y] = count\n",
        "        count  = count + 1\n",
        "    \n",
        "    A = np.zeros((len(a),len(b)))\n",
        "    for edge in edges:\n",
        "        e1 = top_nodes[edge[0]]\n",
        "        e2 = bottom_nodes[edge[1]]\n",
        "        A[e1, e2] = 1\n",
        "    \n",
        "    A = np.dot(A,A.T)\n",
        "#     print(A[:35,:35])\n",
        "    for i in range(0,A.shape[0]):  #making numpy matrix undirected graph type\n",
        "        for j in range(0,A.shape[1]):\n",
        "            if i == j :\n",
        "                A[i,j] = 0\n",
        "            else:\n",
        "                if A[i,j] > 0:\n",
        "                    A[i,j] = 1\n",
        "                    \n",
        "    G=nx.from_numpy_matrix(A)\n",
        "    return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xvz9q8UZ2qE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph = load_restaurant_dataset()\n",
        "\n",
        "nodes = list(graph.nodes)\n",
        "# print(nx.info(graph))\n",
        "non_edges = list(nx.non_edges(graph))\n",
        "edges = list(nx.edges(graph))\n",
        "# print((non_edges))\n",
        "m = len(edges)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjZL1C6haGHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n",
        "from sklearn.manifold import spectral_embedding\n",
        "import node2vec\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import time\n",
        "import os\n",
        "import tensorflow as tf\n",
        "# from gae.optimizer import OptimizerAE, OptimizerVAE\n",
        "# from gae.model import GCNModelAE, GCNModelVAE\n",
        "# from gae.preprocessing import preprocess_graph, construct_feed_dict, sparse_to_tuple, mask_test_edges\n",
        "import pickle\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def get_roc_score(edges_pos, edges_neg, score_matrix, apply_sigmoid=False):\n",
        "\n",
        "    # Edge case\n",
        "    if len(edges_pos) == 0 or len(edges_neg) == 0:\n",
        "        return (None, None, None)\n",
        "\n",
        "    # Store positive edge predictions, actual values\n",
        "    preds_pos = []\n",
        "    pos = []\n",
        "    for edge in edges_pos:\n",
        "        if apply_sigmoid == True:\n",
        "            preds_pos.append(sigmoid(score_matrix[edge[0], edge[1]]))\n",
        "        else:\n",
        "            preds_pos.append(score_matrix[edge[0], edge[1]])\n",
        "        pos.append(1) # actual value (1 for positive)\n",
        "        \n",
        "    # Store negative edge predictions, actual values\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for edge in edges_neg:\n",
        "        if apply_sigmoid == True:\n",
        "            preds_neg.append(sigmoid(score_matrix[edge[0], edge[1]]))\n",
        "        else:\n",
        "            preds_neg.append(score_matrix[edge[0], edge[1]])\n",
        "        neg.append(0) # actual value (0 for negative)\n",
        "        \n",
        "    # Calculate scores\n",
        "    preds_all = np.hstack([preds_pos, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds_pos)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    # roc_curve_tuple = roc_curve(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "    \n",
        "    # return roc_score, roc_curve_tuple, ap_score\n",
        "    return roc_score, ap_score\n",
        "\n",
        "\n",
        "def node2vec_scores(\n",
        "    g_train, train_test_split,\n",
        "    P = 1, # Return hyperparameter\n",
        "    Q = 1, # In-out hyperparameter\n",
        "    WINDOW_SIZE = 10, # Context size for optimization\n",
        "    NUM_WALKS = 10, # Number of walks per source\n",
        "    WALK_LENGTH = 80, # Length of walk per source\n",
        "    DIMENSIONS = 128, # Embedding dimension\n",
        "    DIRECTED = False, # Graph directed/undirected\n",
        "    WORKERS = 8, # Num. parallel workers\n",
        "    ITER = 1, # SGD epochs\n",
        "    edge_score_mode = \"edge-emb\", # Whether to use bootstrapped edge embeddings + LogReg (like in node2vec paper), \n",
        "        # or simple dot-product (like in GAE paper) for edge scoring \"dot-product\"\n",
        "    verbose=1,\n",
        "    ):\n",
        "    if g_train.is_directed():\n",
        "        DIRECTED = True\n",
        "\n",
        "    adj_train, train_edges, train_edges_false, val_edges, val_edges_false, \\\n",
        "        test_edges, test_edges_false = train_test_split # Unpack train-test split\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Preprocessing, generate walks\n",
        "    if verbose >= 1:\n",
        "        print('Preprocessing grpah for node2vec...')\n",
        "    g_n2v = node2vec.Graph(g_train, DIRECTED, P, Q) # create node2vec graph instance\n",
        "    g_n2v.preprocess_transition_probs()\n",
        "    if verbose == 2:\n",
        "        walks = g_n2v.simulate_walks(NUM_WALKS, WALK_LENGTH, verbose=True)\n",
        "    else:\n",
        "        walks = g_n2v.simulate_walks(NUM_WALKS, WALK_LENGTH, verbose=False)\n",
        "    walks = [list(map(str, walk)) for walk in walks]\n",
        "\n",
        "    # Train skip-gram model\n",
        "    model = Word2Vec(walks, size=DIMENSIONS, window=WINDOW_SIZE, min_count=0, sg=1, workers=WORKERS, iter=ITER)\n",
        "\n",
        "    # Store embeddings mapping\n",
        "    emb_mappings = model.wv\n",
        "\n",
        "    # Create node embeddings matrix (rows = nodes, columns = embedding features)\n",
        "    emb_list = []\n",
        "    for node_index in range(0, adj_train.shape[0]):\n",
        "        node_str = str(node_index)\n",
        "        node_emb = emb_mappings[node_str]\n",
        "        emb_list.append(node_emb)\n",
        "    emb_matrix = np.vstack(emb_list)\n",
        "\n",
        "    # Generate bootstrapped edge embeddings (as is done in node2vec paper)\n",
        "        # Edge embedding for (v1, v2) = hadamard product of node embeddings for v1, v2\n",
        "    if edge_score_mode == \"edge-emb\":\n",
        "        \n",
        "        def get_edge_embeddings(edge_list):\n",
        "            embs = []\n",
        "            for edge in edge_list:\n",
        "                node1 = edge[0]\n",
        "                node2 = edge[1]\n",
        "                emb1 = emb_matrix[node1]\n",
        "                emb2 = emb_matrix[node2]\n",
        "                edge_emb = np.multiply(emb1, emb2)\n",
        "                embs.append(edge_emb)\n",
        "            embs = np.array(embs)\n",
        "            return embs\n",
        "\n",
        "        # Train-set edge embeddings\n",
        "        pos_train_edge_embs = get_edge_embeddings(train_edges)\n",
        "        neg_train_edge_embs = get_edge_embeddings(train_edges_false)\n",
        "        train_edge_embs = np.concatenate([pos_train_edge_embs, neg_train_edge_embs])\n",
        "\n",
        "        # Create train-set edge labels: 1 = real edge, 0 = false edge\n",
        "        train_edge_labels = np.concatenate([np.ones(len(train_edges)), np.zeros(len(train_edges_false))])\n",
        "\n",
        "        # Val-set edge embeddings, labels\n",
        "        if len(val_edges) > 0 and len(val_edges_false) > 0:\n",
        "            pos_val_edge_embs = get_edge_embeddings(val_edges)\n",
        "            neg_val_edge_embs = get_edge_embeddings(val_edges_false)\n",
        "            val_edge_embs = np.concatenate([pos_val_edge_embs, neg_val_edge_embs])\n",
        "            val_edge_labels = np.concatenate([np.ones(len(val_edges)), np.zeros(len(val_edges_false))])\n",
        "            \n",
        "\n",
        "        # Test-set edge embeddings, labels\n",
        "        pos_test_edge_embs = get_edge_embeddings(test_edges)\n",
        "        neg_test_edge_embs = get_edge_embeddings(test_edges_false)\n",
        "        test_edge_embs = np.concatenate([pos_test_edge_embs, neg_test_edge_embs])\n",
        "\n",
        "        # Create val-set edge labels: 1 = real edge, 0 = false edge\n",
        "        test_edge_labels = np.concatenate([np.ones(len(test_edges)), np.zeros(len(test_edges_false))])\n",
        "\n",
        "        # Train logistic regression classifier on train-set edge embeddings\n",
        "        edge_classifier = LogisticRegression(random_state=0)\n",
        "        edge_classifier.fit(train_edge_embs, train_edge_labels)\n",
        "\n",
        "        # Predicted edge scores: probability of being of class \"1\" (real edge)\n",
        "        if len(val_edges) > 0 and len(val_edges_false) > 0:\n",
        "            val_preds = edge_classifier.predict_proba(val_edge_embs)[:, 1]\n",
        "        test_preds = edge_classifier.predict_proba(test_edge_embs)[:, 1]\n",
        "\n",
        "        runtime = time.time() - start_time\n",
        "\n",
        "        # Calculate scores\n",
        "        if len(val_edges) > 0 and len(val_edges_false) > 0:\n",
        "            n2v_val_roc = roc_auc_score(val_edge_labels, val_preds)\n",
        "            # n2v_val_roc_curve = roc_curve(val_edge_labels, val_preds)\n",
        "            n2v_val_ap = average_precision_score(val_edge_labels, val_preds)\n",
        "        else:\n",
        "            n2v_val_roc = None\n",
        "            n2v_val_roc_curve = None\n",
        "            n2v_val_ap = None\n",
        "        \n",
        "        n2v_test_roc = roc_auc_score(test_edge_labels, test_preds)\n",
        "        # n2v_test_roc_curve = roc_curve(test_edge_labels, test_preds)\n",
        "        n2v_test_ap = average_precision_score(test_edge_labels, test_preds)\n",
        "\n",
        "\n",
        "    # Generate edge scores using simple dot product of node embeddings (like in GAE paper)\n",
        "    elif edge_score_mode == \"dot-product\":\n",
        "        score_matrix = np.dot(emb_matrix, emb_matrix.T)\n",
        "        runtime = time.time() - start_time\n",
        "\n",
        "        # Val set scores\n",
        "        if len(val_edges) > 0:\n",
        "            n2v_val_roc, n2v_val_ap = get_roc_score(val_edges, val_edges_false, score_matrix, apply_sigmoid=True)\n",
        "        else:\n",
        "            n2v_val_roc = None\n",
        "            n2v_val_roc_curve = None\n",
        "            n2v_val_ap = None\n",
        "        \n",
        "        # Test set scores\n",
        "        n2v_test_roc, n2v_test_ap = get_roc_score(test_edges, test_edges_false, score_matrix, apply_sigmoid=True)\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid edge_score_mode! Either use edge-emb or dot-product.\")\n",
        "\n",
        "    # Record scores\n",
        "    n2v_scores = {}\n",
        "\n",
        "    n2v_scores['test_roc'] = n2v_test_roc\n",
        "    # n2v_scores['test_roc_curve'] = n2v_test_roc_curve\n",
        "    n2v_scores['test_ap'] = n2v_test_ap\n",
        "\n",
        "    n2v_scores['val_roc'] = n2v_val_roc\n",
        "    # n2v_scores['val_roc_curve'] = n2v_val_roc_curve\n",
        "    n2v_scores['val_ap'] = n2v_val_ap\n",
        "\n",
        "    n2v_scores['runtime'] = runtime\n",
        "\n",
        "    return n2v_scores\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRGxiCr9akqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from preprocessing import mask_test_edges"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qerxYpiOa4Fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "adj_sparse = nx.to_scipy_sparse_matrix(graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKvnCG69a8Em",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e89c682d-f189-403c-a396-d4450edf2ad9"
      },
      "source": [
        "train_test_split = mask_test_edges(adj_sparse, test_frac=.2, val_frac=0, prevent_disconnect=False, verbose=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessing...\n",
            "generating test/val sets...\n",
            "creating false test edges...\n",
            "creating false val edges...\n",
            "creating false train edges...\n",
            "final checks for disjointness...\n",
            "creating adj_train...\n",
            "Done with train-test split!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bes9fQl1byis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adj_train, train_edges, train_edges_false, val_edges, val_edges_false, test_edges, test_edges_false = train_test_split # Unpack tuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgB9TQ-qbA2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_train = nx.from_scipy_sparse_matrix(adj_train) # new graph object with only non-hidden edges"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgfq7gqQbDXG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f566261c-52d3-4863-b8ae-eff07305db74"
      },
      "source": [
        "# Inspect train/test split\n",
        "print(\"Total nodes:\", adj_sparse.shape[0])\n",
        "print(\"Total edges:\", int(adj_sparse.nnz/2)) # adj is symmetric, so nnz (num non-zero) = 2*num_edges\n",
        "print(\"Training edges (positive):\", len(train_edges))\n",
        "print(\"Training edges (negative):\", len(train_edges_false))\n",
        "# print(\"Validation edges (positive):\", len(val_edges))\n",
        "# print(\"Validation edges (negative):\", len(val_edges_false))\n",
        "print(\"Test edges (positive):\", len(test_edges))\n",
        "print(\"Test edges (negative):\", len(test_edges_false))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total nodes: 2060\n",
            "Total edges: 58810\n",
            "Training edges (positive): 47048\n",
            "Training edges (negative): 47048\n",
            "Test edges (positive): 11762\n",
            "Test edges (negative): 11762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-ZsP0ScbSMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70e8fe7e-7734-4912-f78a-43754a061979"
      },
      "source": [
        "result = node2vec_scores(g_train,train_test_split, edge_score_mode = \"dot-product\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing grpah for node2vec...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJccXMdofVAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bbd0aff5-e643-49fb-b9ea-280ea8b12f04"
      },
      "source": [
        "print(result)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'test_roc': 0.8471743835634143, 'test_ap': 0.8597332798019579, 'val_roc': None, 'val_ap': None, 'runtime': 87.84371376037598}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz7E7BslivYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "25b61d4f-946c-4b80-b09b-0f6658fed13a"
      },
      "source": [
        "result2 = node2vec_scores(g_train,train_test_split)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing grpah for node2vec...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6E14QRLiz9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f9c0f7b1-21a6-4a91-cc7f-e7966187f2c9"
      },
      "source": [
        "print(result2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'test_roc': 0.867072765028764, 'test_ap': 0.8797375219275716, 'val_roc': None, 'val_ap': None, 'runtime': 91.13219332695007}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}